model:
  base_learning_rate: 4.5e-06
  target: core.models.decoder.unet.RefinementUNet
  params:
    # ckpt_path: ckpts/places256_unet.ckpt
    embed_dim: 256
    input_res: 256
    n_embed: 1024
    image_key: image
    freeze_firststage: false  # set to True if we have pretrained a decoder without the U-net, otherwise set False to train them together
    edconfig:
      padding_free: false
      double_z: false
      z_channels: 256
      resolution: 256
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult:
      - 1
      - 1
      - 2
      - 2
      - 4
      num_res_blocks: 2
      attn_resolutions:
      - 16
      dropout: 0.0
    ddconfig:
      padding_free: false
      double_z: false
      z_channels: 256
      resolution: 512
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult:
      - 1
      - 1
      - 1
      - 2
      - 2
      - 4
      num_res_blocks: 2
      attn_resolutions:
      - 16
      dropout: 0.0
    first_stage_model_type: 'decoder'
    first_stage_config:
      target: core.models.decoder.decoder.PartialDecoder
      params:
        # ckpt_path: ckpts/places256_decoder.ckpt
        embed_dim: 256
        n_embed: 1024
        image_key: image
        restriction: false
        first_stage_model_type: 'vae'
        first_stage_config:
          target: core.models.vqgan.VQModel
          params:
            ckpt_path: ckpts/places256_vqgan1024_BASE.ckpt
            embed_dim: 256
            n_embed: 1024
            ddconfig:
              padding_free: false
              double_z: false
              z_channels: 256
              resolution: 256
              in_channels: 3
              out_ch: 3
              ch: 128
              ch_mult:
              - 1
              - 1
              - 2
              - 2
              - 4
              num_res_blocks: 2
              attn_resolutions:
              - 16
              dropout: 0.0
            lossconfig:
              target: core.modules.losses.DummyLoss
        ddconfig:
          padding_free: false
          double_z: false
          z_channels: 256
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult:
          - 1
          - 1
          - 2
          - 2
          - 4
          num_res_blocks: 2
          attn_resolutions:
          - 16
          dropout: 0.0
        lossconfig:
          target: core.modules.losses.vqperceptual.PIPSWithDiscriminator
          params:
            pixelloss_weight: 0.0
            perceptual_weight: 0.1
            r1_weight: 1.0
            disc_conditional: false
            disc_in_channels: 4
            disc_start: 60000
            disc_weight: 1.0
    lossconfig:
      target: core.modules.losses.vqperceptual.PIPSWithDiscriminator
      params:
        pixelloss_weight: 0.1
        perceptual_weight: 0.1
        r1_weight: 1.0
        disc_conditional: false
        disc_in_channels: 4
        disc_start: 60000
        disc_weight: 1.0
data:
  target: train.DataModuleFromConfig
  params:
    batch_size: 4
    train:
      target: core.data.places365.Places
      params:
        dataroot: /home/chenh/data/data_large
        crop_size: 512
        rescale: true
        rescale_size: 512
        split: train
